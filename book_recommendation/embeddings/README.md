# ğŸ“¦ Embedding Module

ë‹¤ì–‘í•œ ë¬¸ì¥ ì„ë² ë”© ëª¨ë¸ê³¼ ì„ë² ë”© ë²¡í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” **í’€ë§(pooling)** ì „ëµì„ í¬í•¨í•œë‹¤. 
SBERT, KoSimCSEì™€ ê°™ì€ ì‚¬ì „í•™ìŠµëœ ëª¨ë¸ì„ ì´ìš©í•˜ì—¬ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜í•œ ë’¤,  
í‰ê· (MEAN) ë˜ëŠ” Self-Attention ë°©ì‹ìœ¼ë¡œ ë¬¸ì¥ ë²¡í„°ë¥¼ í†µí•©í•œë‹¤. 

---

## ğŸ“‚ íŒŒì¼ êµ¬ì„±

| íŒŒì¼ëª… | ì„¤ëª… |
|--------|------|
| `sbert_embedding.py` | SBERT(Sentence-BERT)ë¥¼ í™œìš©í•œ ì„ë² ë”© í´ë˜ìŠ¤ |
| `kosimcse_embedding.py` | KoSimCSE ëª¨ë¸ì„ ì´ìš©í•œ ë¬¸ì¥ ì„ë² ë”© |
| `embedding_pooling.py` | ë¬¸ì¥ ì„ë² ë”© ë²¡í„°ì— ëŒ€í•œ Mean / Self-Attention í’€ë§ ê¸°ë²• |

---

## ğŸ“˜ í´ë˜ìŠ¤ ì„¤ëª…

### ğŸ”¹ `SBERTModel`

```python
from embeddings.sbert_embedding import SBERTModel
model = SBERTModel()
embeddings = model.encode(sentences, return_all=True)